<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="X-UA-Compatible" content="IE=edge">
  <title>System Design</title>
  <meta name="description" content="System Design - hellcy">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="short icon" href="/sitelogo.jpg">
  <link rel="stylesheet" href="/css/apollo.css">
</head>
<body>
  <header>
    <a href="/" class="logo-link"><img src="/sitelogo.jpg"></a>
    <ul class="nav nav-list">
      <li class="nav-list-item">
        <a href="/" target="_self" class="nav-list-link">Blog</a>
      </li>
      <li class="nav-list-item">
        <a href="https://github.com/hellcy" target="_blank" class="nav-list-link">Github</a>
      </li>
    </ul>
  </header>
  <section class="container">
    <div class="post">
      <article class="post-block">
        <h1 class="post-title">System Design</h1>
        <div class="post-time">June 12, 2020</div>
        <div class="post-content">
          <h2 id="u6587_u7AE0_u7ED3_u6784">
            <a href="#u6587_u7AE0_u7ED3_u6784" class="headerlink" title="Scalability Harvard Web Development Course"></a>Scalability Harvard Web Development Course
          </h2>
          <h3>Vertical Scaling</h3>
          <p>增加服务器的CPU，内存，硬盘等，但总会不够用</p>
          <ol>
            <li>CPU: cores, L2 cache...</li>
            <li>Disk: PATA, SATA, SAS, RAID</li>
            <li>RAID(Redundent array of independent disks)
              <ol>
                <li>RAID 0 :如果你有n块磁盘，原来只能同时写一块磁盘，写满了再下一块，做了RAID 0之后，n块可以同时写，速度提升很快，但由于没有备份，可靠性很差。n最少为2。</li>
                <li>RAID 1: 正因为RAID 0太不可靠，所以衍生出了RAID1。如果你有n块磁盘，把其中n/2块磁盘作为镜像磁盘，在往其中一块磁盘写入数据时，也同时往另一块写数据。坏了其中一块时，镜像磁盘自动顶上，可靠性最佳，但空间利用率太低。n最少为2。</li>
                <li>RAID 10: 是RAID 0 和RAID 1 的结合，同时写入n/2的硬盘并将剩下n/2作为备份，可靠性和速度都有，但是需要两倍的钱。</li>
                <li>RAID 3：为了说明白RAID 5，先说RAID 3.RAID 3是若你有n块盘，其中1块盘作为校验盘，剩余n-1块盘相当于作RAID 0同时读写，当其中一块盘坏掉时，可以通过校验码还原出坏掉盘的原始数据。这个校验方式比较特别，奇偶检验，1 XOR 0 XOR 1=0，0 XOR 1 XOR 0=1，最后的数据时校验数据，当中间缺了一个数据时，可以通过其他盘的数据和校验数据推算出来。但是这有个问题，由于n-1块盘做了RAID 0，每一次读写都要牵动所有盘来为它服务，而且万一校验盘坏掉就完蛋了。最多允许坏一块盘。n最少为3.</li>
                <li>RAID 5：在RAID 3的基础上有所区别，同样是相当于是1块盘的大小作为校验盘，n-1块盘的大小作为数据盘，但校验码分布在各个磁盘中，不是单独的一块磁盘，也就是分布式校验盘，这样做好处多多。最多坏一块盘。n最少为3.</li>
                <li>RAID 6：在RAID 5的基础上，又增加了一种校验码，和解方程似的，一种校验码一个方程，最多有两个未知数，也就是最多坏两块盘。</li>
              </ol>
            </li>
            <li>RAM</li>
          </ol>
          <h3>Horizontal Scaling</h3>
          <p>增加更多的服务器，而不是提升每个服务器的配置。当我们拥有多于一个服务器时，当用户向服务器发送请求时，我们需要一个load balancer去将进来的request平均分配给所有的服务器。load balancer拥有一个public IP
          。而每一个服务器有一个private IP，他们不需要public IP</p>
          <h3>Load Balancing</h3>
          <p>如何给服务器平均分配request？我们可以将所有可用的服务器IP列出来，第一个request给第一个服务器，第二个request给第二个服务器，以此类推直到回到第一个，然后循环，这种方法叫做round-robin，优点是他不需要主动询问服务器的当前状态如何。</p>
          <h3>Caching</h3>
          <p>当用户通过load balancer登录到一号服务器时，他的登录信息如果保存在一号服务器，那么在他下一个request被分配到其他服务器时，他就需要再次登录，如果他在使用一个购物网站，他将一件商品加入到一号服务器的购物车中，然后又在二号服务器登录却找不到他的购物车，也不能结帐，这就会成为一个大问题</p>
          <h3>Shared Session State(Sticky session)</h3>
          <p>我们可以将session，也就是用户信息储存在另外一个服务器中</p>
          <p>Shared Storage</p>
          <p>FC (Fiber Channel), iSCSI, MySQL, NFS</p>
          <p>Replicate your database, use more than one database to store sessions in case one goes down</p>
          <h3>Cookie</h3>
          <p>当用户首次登陆时，load balancer可以想用户电脑中加入一个cookie，包含一些加密的服务器信息，所以当用户在短时间内再次访问时，load balancer就知道该将用户的请求发送到哪个服务器</p>
          <h3>Load Balancer</h3>
          <p>Software: ELB(Amazon's Elastic Load Balancer), HAProxy(High Availability Proxy), LVS(Linux Virtual Server)</p>
          <p>Hardware: Barracuda, Cisco, Citrix, F5</p>
          <h3>PHP Accelerators</h3>
          <p>当我们在调用python程序时，我们需要先将以py结尾的代码文件编译成可直接执行的文件，然后再运行可执行文件得到结果。这样做的目的是当我们想再次得到结果时，我们不需要再次编译，可以直接运行执行文件。</p>
          <p>这样做可以提升效率，但是如果我们有任何的代码改动，我们就需要重新编译。</p>
          <p>PHP Accelerators有一样的逻辑，用户在发送相同的请求时，网站会直接运行可执行文件以提升速度</p>
          <h3>Caching</h3>
          <p>.html</p>
          <p>Caching就是一种将你经常访问的数据提前保存到你的电脑上以便下次快速显示的技术。对于PHP来说，HTML网页是自动生成的，意味着每次用户访问时PHP都会重新生成一个新的重复的HTML文件。</p>
          <p>如果我们将所有的HTML网页都事先编译好储存在服务器上，用户访问时就可以快速拿到这些静态网页，因为不需要每次都进行编译。这就是一种Caching</p>
          <p>这样做的坏处是，当你需要更改整个网站的风格时，你就需要更改所有的HTML文件。</p>
          <p>MySQL Query Cache：MySQL会将一些query的结果caching，第一次运行时如果你的table很大，或者你要找的column没有index，他会运行一段时间，但是下次你就会更快的看到结果</p>
          <p>memcached</p>
          <p>memory cache， 内存的读写要比硬盘快很多，所以我们如果有一百万个用户，服务器SQL拿到一个用户数据可能会需要很长时间，我们可以将这个用户数据保存在memory里面，下次就可以快速得到</p>
          <p>下面是PHP将用户数据保存到memcache的代码</p>
          <pre>
            $memcache = memchache_connect(HOST, PORT);
            $user = memcache_get($memcache, $id);
            // 如果内存里面没有这个用户的id，我们就从数据库中拿取，之后把他添加到内存中
            if (is_null($user))
            {
              $bdh = new PDO(DSN, USER, PASS;
              $result = $dbh->query("SELECT * FROM users WHERE id = $id");
              $user = $result->fetch(PDO:FETCH_ASSOC); // this is to get the associated array of data(username, email address,...)
              memcache_set($memcache, $user['id'], $user)
            }
          </pre>
          <p>如果我们一直将数据添加到内存中，内存总有一天会不够用，这时我们就需要删除一些数据来释放空间，我们可以删除最早的数据（LRU， Least Recent Used）或者最少用到的数据(LFU, Least Frequent Used)</p>
          <h3>Data Replication: Master: slave</h3>
          <p>主从关系的服务器复制，所有的附属服务器要从主服务器中拿取数据，要将新数据写入主服务器，一切以主服务器为准，优点在于当主服务器down机时，我们可以自动化一个过程：因为所有服务器的数据都是一样的，我们可以将一个附属服务器晋升为新的主服务器。以保证服务不间断</p>
          <p>适用于读多于写的网站，所有的读取都去附属服务器，所有的写入都去主服务器</p>
          <p>缺点是当主服务器down机时，写入会短暂失效一段时间直到其中一个附属服务器成为新的主服务器</p>
          <h3>Data Replication: Master: Master</h3>
          <p>当其中一个主服务器失效时，我们还有另外一个，从而保证不会有服务间断的时间.同样，读取请求发送到附属服务器，写入发送到主服务器</p>
          <img src="1.png">
          <p>上面的图片还是有一个缺点，就是如果load balancer失效了，整个服务还是会断开。所以我们需要有两个相同作用的load balancer</p>
          <p>Load Balancer: active: active</p>
          <p>每个load balancer都负责分配任务，并且他们会不断的每个一段时间向另一个load balancer发送一个heart beat，以证明自己的存在。如果任何一个load balancer没有收到另一个的心跳，他就将负责所有的流量</p>
          <p>Load Balancer: active: passive</p>
          <p>与之前相似，只不过一开始只有一个load balancer负责所有的流量，并且向passive的load balancer发送心跳，如果passive load balancer没有接收到心跳，他就把自己提升为active load balancer，并开始负责所有的任务。</p>
          <h3>Partitioning</h3>
          <img src="2.png">
          <p>将整个服务系统复制，供多个不同的客户使用，Facebook早期将不同学校的用户分到不同的服务器中，类似于harvard.facebook.com, MIT.facebook.com,以此来降低流量的压力。这样的话当你想联系不同大学的人时，就会有些困难。另外一个例子是我们可以将用户分配到不同的服务器中based on他们的名字，A-M到第一个，N-Z到第二个</p>
          <h3>High Availiability</h3>
          <img src="2.png">
          <p>不同的服务器之间互相听取对方的心跳，并随时准备take over当另外的服务器offline</p>
          <p>网络层和web server层之间需要load balancer web server层和DB层之间也需要load balancer，load balancer会将第一个返回的DB的信息加到Cookie中返回给用户，这样用户在Cookie过期之前都会被route到同一个服务器, 这样就保证用户不会被分配到另一个服务器里面却没有他最新的数据，服务器之间也会相互同步。 每一层之间的load balancer也需要多个以保证一个offlice不会影响全局。可以使用active active或者active passive， DB也需要多个，可以是Master Master或者Master Slave. 最后就是这样的一个Data center也需要多个，就像AWS一样在US， Aisa， Europe都会有服务器。</p>
          <h3>Security</h3>
          <p>什么样的traffic可以进入data center？TCP 80和443</p>
          <p>什么样的traffic可以从load balancer到web server？TCP 80. 我们可以在load balancer中加入证书并解密所有的traffic，然后之后的所有traffic都保持不加密的状态，因为我们已经进入到data center，不需要在担心安全问题，所以让load balancer去做揭秘这样的繁重工作，web server只负责应付无秘traffic</p>
          <p>什么样的traffic从web server到DB？一般的SQL queries 也是 TCP 3306（port number 3306 is the default number SQL query uses）</p>
          <p>注意web server之间并不能交流。</p>
          <p>我们之所以设置这些规则，只让这些port的traffic进入，是因为加如其中一个web server被攻占了，那么它也只能向DB发送SQL请求，不能向其他web server发送443或者80请求，将破坏控制在最小。</p>
          <ol>
            <li><a href="https://www.youtube.com/watch?v=-W9F__D3oY4" target="_blank">CS75 (Summer 2012) Lecture 9 Scalability Harvard Web Development David Malan</a></li>
          </ol>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <h2 id="u6587_u7AE0_u7ED3_u6784">
            <a href="#u6587_u7AE0_u7ED3_u6784" class="headerlink" title="Scalability for Dummies"></a>Scalability for Dummies
          </h2>
          <h3>Clones</h3>
          <ol>
            <li>用户的请求可以被不同的服务器接受</li>
            <li>每个服务器保存的数据应该是一样的</li>
            <li>用户数据Session需要被保存在另一个不用的地方，可以是另外一个服务器或者是Cache（Redis）</li>
            <li>Capistrano可以用来保持所有服务器的同步</li>
            <li>当新建一个服务器时，把数据从一个super clone里镜像复制过来</li>
          </ol>
          <h3>Database</h3>
          <ol>
            <li>用户的请求可以被不同的服务器接受</li>
            <li>每个服务器保存的数据应该是一样的</li>
            <li>用户数据Session需要被保存在另一个不用的地方，可以是另外一个服务器或者是Cache（Redis）</li>
            <li>Capistrano可以用来保持所有服务器的同步</li>
            <li>当新建一个服务器时，把数据从一个super clone里镜像复制过来</li>
          </ol>
          <h2 id="u6587_u7AE0_u7ED3_u6784">
            <a href="#u6587_u7AE0_u7ED3_u6784" class="headerlink" title="Performance vs scalability"></a>Performance vs scalability
          </h2>
          <p>What is it that we really mean by scalability? A service is said to be scalable if when we increase the resources in a system, it results in increased performance in a manner proportional to resources added. Increasing performance in general means serving more units of work, but it can also be to handle larger units of work, such as when datasets grow.</p>
          <p>Why is scalability so hard? Because scalability cannot be an after-thought. It requires applications and platforms to be designed with scaling in mind, such that adding resources actually results in improving the performance or that if redundancy is introduced the system performance is not adversely affected.</p>
          <p>在扩展服务的时候，有些资源算的快，有些算的慢，这可能会导致问题或者算的快的资源无法发挥其作用。A second problem area is that growing a system through scale-out generally results in a system that has to come to terms with heterogeneity. Resources in the system increase in diversity as next generations of hardware come on line, as bigger or more powerful resources become more cost-effective or when some resources are placed further apart. Heterogeneity means that some nodes will be able to process faster or store more data than other nodes in a system and algorithms that rely on uniformity either break down under these conditions or underutilize the newer resources.</p>
          <ol>
            <li><a href="https://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html" target="_blank">A word on scalability</a></li>
          </ol>
          <h2 id="u6587_u7AE0_u7ED3_u6784">
            <a href="#u6587_u7AE0_u7ED3_u6784" class="headerlink" title="Latency vs throughput"></a>Latency vs throughput
          </h2>
          <p>Latency is the time to perform some action or to produce some result.</p>
          <p>Throughput is the number of such actions or results per unit of time.</p>
          <p>Generally, you should aim for maximal throughput with acceptable latency.</p>
          <ol>
            <li><a href="https://community.cadence.com/cadence_blogs_8/b/sd/posts/understanding-latency-vs-throughput" target="_blank">Understanding latency vs throughput</a></li>
          </ol>
          <h2 id="u6587_u7AE0_u7ED3_u6784">
            <a href="#u6587_u7AE0_u7ED3_u6784" class="headerlink" title="Availability vs consistency"></a>Availability vs consistency(可靠性与一致性), CAP Theorem
          </h2>
          <p>In a distributed computer system, you can only support two of the following guarantees:</p>
          <ul>
            <li>Consistency - Every read receives the most recent write or an error</li>
            <li>Availability - Every request receives a response, without guarantee that it contains the most recent version of the information</li>
            <li>Partition Tolerance - The system continues to operate despite arbitrary partitioning due to network failures</li>
          </ul>
          <p>Networks aren't reliable, so you'll need to support partition tolerance. You'll need to make a software tradeoff between consistency and availability.</p>
          <p>CP - consistency and partition tolerance: Waiting for a response from the partitioned node might result in a timeout error. CP is a good choice if your business needs require atomic reads and writes.</p>
          <p>AP - availability and partition tolerance: Responses return the most recent version of the data available on a node, which might not be the latest. Writes might take some time to propagate when the partition is resolved. AP is a good choice if the business needs allow for eventual consistency or when the system needs to continue working despite external errors.</p>
          <ol>
            <li><a href="https://robertgreiner.com/cap-theorem-revisited/" target="_blank">CAP theorem revisited</a></li>
          </ol>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
          <p></p>
        </div>
      </article>
    </div>
  </section>
  <footer>
    <div class="paginator">
      <a href="/2020/05/10/Data_Structures_Advanced/" class="next">下一篇</a>
    </div>
  </footer>
    <div id="disqus_thread"></div>
    <script>
  var disqus_shortname = 'hellcy';
  
  var disqus_url = 'https://hellcy.github.io/2020/06/12/System_Design/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//go.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <script id="dsq-count-scr" src="//https-hellcy-github-io.disqus.com/count.js" async></script>
    <script src="https://cdn.bootcss.com/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  </body>
</html>